## Hi there 👋

 I'm Dimitri — Future AI Safety Engineer

🎯 Aspiring to build safe, ethical, and robust artificial intelligence systems.  
📍 Currently focused on foundational skills in Python, Deep Learning, and AI Alignment.

---

## 🚀 What I’m working on
- 📚 **AI Python for Beginners** bootcamp (DeepLearning.AI)
- 🔭 Preparing for advanced training: FastAI / PyTorch / Transformers
- 🧪 Building small, AI-enhanced productivity tools

## 🔍 Interests
AI Safety • AI Alignment • LLMs • Deep Learning • Adversarial ML • AI Ethics & Law

## 📂 Upcoming Projects
- `ai-python-for-beginners`: Notebooks and projects from the bootcamp
- `ai-productivity-scripts`: Automation & smart tools using LLMs
- `deep-learning-lab`: Vision, NLP & Transformers experiments
- `ai-safety-journal`: Notes and learning logs on safety, alignment, robustness

## 🧠 Long-term goal
Becoming an expert in AI Safety, Adversarial ML, and AI Law (Adversarial Law).  
Contributing to research, robust systems, and policy on beneficial AI.

---

## 🌐 Connect with me

• [LinkedIn](https://www.linkedin.com/in/dimitri-aisafety/)
• [GitHub](https://github.com/DimitrAiSafety) 
• [Twitter](https://x.com/AdvAlignAI)

---

<br/>

# 🇫🇷 Salut, je suis Dimitri — Futur expert en AI Safety

🎯 Mon objectif : concevoir des systèmes d’intelligence artificielle sûrs, éthiques et robustes.  
📍 Actuellement en formation intensive sur Python, le Deep Learning, et l’alignement des IA.

---

## 🚀 Ce sur quoi je travaille
- 📚 Bootcamp **AI Python for Beginners** (DeepLearning.AI)
- 🔭 Préparation aux formations avancées : FastAI / PyTorch / Transformers
- 🧪 Création d’outils intelligents pour la productivité

## 🔍 Domaines d’intérêt
AI Safety • Alignement IA • LLMs • Deep Learning • Sécurité / IA Adversaire • Éthique & Droit de l’IA

## 📂 Projets à venir
- `ai-python-for-beginners` : Notebooks & projets du bootcamp
- `ai-productivity-scripts` : Automatisations intelligentes avec LLMs
- `deep-learning-lab` : Vision, NLP & Transformers
- `ai-safety-journal` : Journal de bord sur la sécurité et l’alignement de l’IA

## 🧠 Objectif long terme
Devenir expert en sécurité des IA, IA Adversaire, et droit de l’IA.  
Contribuer à la recherche, au développement de systèmes robustes, et à la régulation d’une IA bénéfique.

---

## 🌐 Me retrouver
• [LinkedIn](https://www.linkedin.com/in/dimitri-aisafety/)
• [GitHub](https://github.com/DimitrAiSafety) 
• [Twitter](https://x.com/AdvAlignAI)


<!--
**DimitriAiSafety/DimitriAiSafety** is a ✨ _special_ ✨ repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- 🔭 I’m currently working on ...
- 🌱 I’m currently learning ...
- 👯 I’m looking to collaborate on ...
- 🤔 I’m looking for help with ...
- 💬 Ask me about ...
- 📫 How to reach me: ...
- 😄 Pronouns: ...
- ⚡ Fun fact: ...
-->
